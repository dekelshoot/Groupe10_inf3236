{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9mYOgrj7VeZ"
      },
      "source": [
        "# GROUPE 10 inf3236\n",
        ". TCHOUPE KENGNE DEKEL JUNIOR 19M2394 \\\n",
        ". NKOUNGHAWE TOMEYUM ROSALIE CORINE 19M2333 \\\n",
        ". BAPOLA AMASSA RICHIL PERRIN 19M2661 \\\n",
        ". OBAMA MEVOUNGOU DRYSTAN GODGIFT 19M2132 \n",
        "\n",
        "## Classificateur de courrier indésirable avec KNN — From Scratch (Python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlC-rC_U8uWR"
      },
      "source": [
        "## Type de similitude \n",
        "\n",
        "Dans le cadre de la classification des e-mails (spam ou jambon), les caractéristiques à comparer sont les fréquences d’un mot dans chaque email. La distance euclidienne est utilisée pour déterminer la similitude entre deux courriels; plus la distance est petite, plus elle est similaire. La formule de distance euclidienne utilisée dans l’algorithme est la suivante :\n",
        "\n",
        "$D(a,b) = \\sqrt{\\sum_{i=0}^n (b_i -a_i)^2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWVtMMHQ7wi-"
      },
      "source": [
        " ## Pseudo code\n",
        "\n",
        "1. Chargez les e-mails de spam et de jambon\n",
        "2. Supprimer la ponctuation et les symboles courants\n",
        "3. Mettre en minuscule toutes les lettres\n",
        "4. Supprimez les mots vides (mots très courants comme les pronoms, les articles, etc.)\n",
        "5. Divisez les e-mails en e-mails d'entrainement  et en e-mails de test\n",
        "6. Pour chaque e-mail de test, calculez la similarité entre celui-ci et tous les e-mails de formation\n",
        "  1. Pour chaque mot qui existe dans l'e-mail de test ou l'e-mail de formation, comptez sa fréquence dans les deux e-mails\n",
        "  2. calculer la distance euclidienne entre les deux e-mails pour déterminer la similarité\n",
        "7. Trier les e-mails par ordre croissant de distance euclidienne\n",
        "8. Sélectionnez les k voisins les plus proches (distance la plus courte)\n",
        "9. Attribuez la classe la plus fréquente dans les k plus proches voisins sélectionnés au nouvel e-mail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWRu61EyHnV4"
      },
      "source": [
        "## Bibliothèques utilisées"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MR_cRf1V7Yqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592baa64-6a80-40c1-8c22-ecc788d03fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os ## pour manipuler les fichiers\n",
        "import string ## pour avoir la liste des ponctuations\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords ## pour avoir la liste des mots vides \n",
        "from sklearn.model_selection import train_test_split ## pour diviser les données(train, test)\n",
        "from sklearn.metrics import accuracy_score ## pour calculer la precision du model\n",
        "import numpy as np ## pour manipuler les tableaux avancés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhVIw1RgJATw"
      },
      "source": [
        "## 1. Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieM0cJQ7KavW",
        "outputId": "ad454b2c-989f-4f56-e77e-09745bdb878b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "location = \"drive/MyDrive/colab_notebooks/colab_notebooks/inf3236/enron2\"\n",
        "location2 = \"drive/MyDrive/colab_notebooks/colab_notebooks/inf3236/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bXQRygdujNy-"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    print(\"Chargement des données...\")\n",
        "    \n",
        "    ## récupérons tous les noms de fichiers des fichiers texte dans\n",
        "    ## chacun des dossiers ham et spam et les stocker dans ham_files_location\n",
        "    ## et spam_files_location respectivement.\n",
        "    ham_files_location = os.listdir(location+\"/ham\")\n",
        "    spam_files_location = os.listdir(location+\"/spam\")\n",
        "    data = []  #liste pour stocker chaque texte d’e-mail et son étiquette correspondante.\n",
        "    # Load ham email\n",
        "    ## Nous parcourons la liste des noms de fichiers texte ham, utilisons open() pour\n",
        "    ## ouvrir un fichier, puis utilisons str(f.read()) pour lire le texte de l’e-mail\n",
        "    ## sous forme de chaîne et le stockons dans du texte variable. Une liste faite de texte\n",
        "    ## et l’étiquette correspondante « jambon » sont ajoutées aux données de la liste.\n",
        "    for file_path in ham_files_location:\n",
        "        f = open(location+\"/ham/\" + file_path, \"r\")\n",
        "        text = str(f.read())\n",
        "        data.append([text, \"ham\"])\n",
        "    # Load spam email\n",
        "    for file_path in spam_files_location:\n",
        "        f = open(location+\"/spam/\" + file_path, \"r\")  ## ouverture du fichier\n",
        "        text = str(f.read()) ## lecture du fichier\n",
        "        data.append([text, \"spam\"])   ## ajout du feature et du label au jeu de donnée\n",
        "        \n",
        "    ## Les données de liste sont transformées en tableau numpy, pour permettre une \n",
        "    ## meilleure manipulation du tableau ultérieurement. les données sont ensuite renvoyées.\n",
        "    data = np.array(data)\n",
        "    \n",
        "    print(\"flag 1: données chargées\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUwQBoddH_5Q"
      },
      "source": [
        "## 2. Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7Bjt25ZKjNzV"
      },
      "outputs": [],
      "source": [
        "# Prétraitement des données : suppression du bruit\n",
        "def preprocess_data(data):\n",
        "    print(\"Prétraitement des données ...\")\n",
        "    \n",
        "    punc = string.punctuation           # liste de ponctuation\n",
        "    sw = stopwords.words('english')     # liste de stopwords\n",
        "    for record in data:\n",
        "        # Supprimer la ponctuation et les symboles courants\n",
        "        for items in punc:\n",
        "            record[0]=record[0].replace(items,\"\") ## renplacer chaque ponctuation par une chaine vide\n",
        "        # mettre toutes les lettres en miniscule et supression des stopwords\n",
        "        splittedWords = record[0].split()\n",
        "        newText = \"\"\n",
        "        for word in splittedWords:\n",
        "            if word not in sw:\n",
        "                word = word.lower() ## mise des lettres en miniscule\n",
        "                newText = newText + \" \" + word  \n",
        "        record[0] = newText\n",
        "        \n",
        "    print(\"flag 2:données prétraités\")        \n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAiROeGFjNzX"
      },
      "source": [
        "## 3. Division des données en ensembles d'entrainement et de test\n",
        "L’ensemble de données est divisé en un ensemble de formation (73 %) et un ensemble de tests (27 %)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Rabl2Xh6jNzY"
      },
      "outputs": [],
      "source": [
        "# Diviser l'ensemble de données d'origine en un ensemble \n",
        "#de données d'entraînement et un ensemble de données de test\n",
        "def split_data(data):\n",
        "    print(\"division des données...\")\n",
        "    \n",
        "    features = data[:, 0]   # tableau contenant tous les corps de texte des e-mails\n",
        "    labels = data[:, 1]     # tableau contenant les étiquettes correspondantes\n",
        "    print(labels)\n",
        "    training_data, test_data, training_labels, test_labels =\\\n",
        "        train_test_split(features, labels, test_size = 0.27, random_state = 42)\n",
        "    \n",
        "    print(\"flag 3: données divisées\")\n",
        "    return training_data, test_data, training_labels, test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hskuj8XjNza"
      },
      "source": [
        "# L’algorithme KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB4v8laAjNzb"
      },
      "source": [
        "## get_count()\n",
        "Cette fonction prend un seul texte d’e-mail et le divise à l’aide de split(). \n",
        "La fréquence d’occurrence de chaque mot dans l’e-mail est comptée et enregistrée dans wordCounts, \n",
        "qui est de type de données de dictionnaire. Le dictionnaire wordCounts est ensuite renvoyé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YwrC3t_8jNzc"
      },
      "outputs": [],
      "source": [
        "def get_count(text):\n",
        "    wordCounts = dict()\n",
        "    for word in text.split():\n",
        "        if word in wordCounts:\n",
        "            wordCounts[word] += 1\n",
        "        else:\n",
        "            wordCounts[word] = 1\n",
        "    \n",
        "    return wordCounts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1bAGVzAjNzc"
      },
      "source": [
        "## euclidean_difference()\n",
        "Cette fonction prend en compte un dictionnaire du nombre de mots d’un test_WordCounts d’e-mail de test et un autre dictionnaire d’un e-mail d'entrainement, training_wordCounts. total stocke la somme de la différence au carré de la fréquence d’un mot dans l’e-mail de test et de formation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fDtBgy49jNze"
      },
      "outputs": [],
      "source": [
        "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
        "    total = 0\n",
        "    for word in test_WordCounts:\n",
        "        if word in test_WordCounts and word in training_WordCounts:\n",
        "            total += (test_WordCounts[word] - training_WordCounts[word])**2\n",
        "            del training_WordCounts[word]\n",
        "        else:\n",
        "            total += test_WordCounts[word]**2\n",
        "    for word in training_WordCounts:\n",
        "        total += training_WordCounts[word]**2\n",
        "    return total**0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVaO064YjNze"
      },
      "source": [
        "## get_class()\n",
        "Cette fonction prend en compte la liste des K voisins les plus proches sélectionnés pour déterminer la classe de l’e-mail de test actuel. spam_count et ham_count stockons la fréquence d’occurrence de chaque étiquette « spam » et étiquette « jambon » respectivement chez les voisins les plus proches sélectionnés par K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BL7FwQ73jNzf"
      },
      "outputs": [],
      "source": [
        "def get_class(selected_Kvalues):\n",
        "    spam_count = 0\n",
        "    ham_count = 0\n",
        "    for value in selected_Kvalues:\n",
        "        if value[0] == \"spam\":\n",
        "            spam_count += 1\n",
        "        else:\n",
        "            ham_count += 1\n",
        "    if spam_count > ham_count:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return \"ham\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7RoDsxtjNzh"
      },
      "source": [
        "## knn_classifier()\n",
        "Il s’agit de la fonction de classificateur KNN. Il prend en compte l’e-mail de formation, les étiquettes de formation, les données de test, la valeur K et le nombre d’e-mails de test à tester sur les 27% d’e-mails de test d’origine. résultat est la liste qui contiendrait les étiquettes prédites. le compteur sera simplement utilisé à des fins d’affichage pour indiquer la progression lorsque le programme est exécuté."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kghmjTO2jNzi"
      },
      "outputs": [],
      "source": [
        "def knn_classifier(training_data, training_labels, test_data, K, tsize):\n",
        "    print(\"Running KNN Classifier...\")\n",
        "    \n",
        "    result = []\n",
        "    counter = 1\n",
        "    # word counts for training email\n",
        "    training_WordCounts = [] \n",
        "    for training_text in training_data:\n",
        "        training_WordCounts.append(get_count(training_text))\n",
        "    for test_text in test_data:\n",
        "        similarity = [] # List of euclidean distances\n",
        "        test_WordCounts = get_count(test_text)  # word counts for test email\n",
        "        # Getting euclidean difference \n",
        "        for index in range(len(training_data)):\n",
        "            euclidean_diff =\\\n",
        "                euclidean_difference(test_WordCounts, training_WordCounts[index])\n",
        "            similarity.append([training_labels[index], euclidean_diff])\n",
        "            # Sort list in ascending order based on euclidean difference\n",
        "            similarity = sorted(similarity, key = lambda i:i[1])\n",
        "            # Select K nearest neighbours\n",
        "            selected_Kvalues = [] \n",
        "            for i in range(K):\n",
        "                selected_Kvalues.append(similarity[i])\n",
        "            # Predicting the class of email\n",
        "            result.append(get_class(selected_Kvalues))\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKeFwji0jNzj"
      },
      "source": [
        " ## fonction main()\n",
        " C’est la fonction principale où le programme commence à s’exécuter. C’est là que tout est mis en place. La fonction principale prend la valeur K. Tout d’abord, tous les e-mails sont chargés à l’aide de load_data(), puis stockés dans des données. Les e-mails sont ensuite prétraités à l’aide de preprocess_data() et stockés à nouveau dans les données. les données sont ensuite divisées en training_data, test_data, training_labels et test_labels à l’aide de split_data()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "e_-MSQEdjNzj"
      },
      "outputs": [],
      "source": [
        "def main(K):\n",
        "    data = load_data()\n",
        "    data = preprocess_data(data)\n",
        "    training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "    tsize = len(test_data)\n",
        "    result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize) \n",
        "    accuracy = accuracy_score(test_labels[:tsize], result)\n",
        "    print(\"training data size\\t: \" + str(len(training_data)))\n",
        "    print(\"test data size\\t\\t: \" + str(len(test_data)))\n",
        "    print(\"K value\\t\\t\\t\\t: \" + str(K))\n",
        "    print(\"Samples tested\\t\\t: \" + str(tsize))\n",
        "    print(\"% accuracy\\t\\t\\t: \" + str(accuracy * 100))\n",
        "    print(\"Number correct\\t\\t: \" + str(int(accuracy * tsize)))\n",
        "    print(\"Number wrong\\t\\t: \" + str(int((1 - accuracy) * tsize)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main(11)"
      ],
      "metadata": {
        "id": "99To6jBbn8m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5-KfAPwojNzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2d2dce-92d8-4b40-8f40-949f7e463a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/colab_notebooks/colab_notebooks/inf3236/'\n",
            "/content/drive/MyDrive/colab_notebooks/colab_notebooks/inf3236\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/colab_notebooks/colab_notebooks/inf3236/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVcTS_wMoSAK",
        "outputId": "56c59425-f82f-45ae-e393-f35f4f434b55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[0m\u001b[01;34menron2\u001b[0m/   TP1.ipynb   TP2.ipynb  'TPE3(KNN classifier).ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = \"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\"\n",
        "username = \"dekelshoot\"\n",
        "useremail = \"juniortchoupe5@gmail.com\"\n",
        "repository = \"Groupe10_inf3236\"\n",
        "!git config --global user.email useremail\n",
        "!git config --global user.name  username \n",
        "!git add  \"TPE3(KNN classifier).ipynb\"\n",
        "\n",
        "!git status\n",
        "!git commit -m \"TPE3(KNN classifier) Machine Learning \""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVD4YNTUF5yb",
        "outputId": "1c25c8b8-fc69-4911-f680-008c20553e09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git reset HEAD <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   TPE3(KNN classifier).ipynb\u001b[m\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   TP1.ipynb\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mTP2.ipynb\u001b[m\n",
            "\t\u001b[31menron2/\u001b[m\n",
            "\n",
            "[master a988fc9] TPE3(KNN classifier) Machine Learning\n",
            " 1 file changed, 1 insertion(+)\n",
            " create mode 100644 TPE3(KNN classifier).ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://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@github.com/dekelshoot/projet.git\n",
        "!git remote -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEzI7_VLGFHk",
        "outputId": "98e45119-f4ab-411a-9564-06adae3c8179"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: git remote add [<options>] <name> <url>\n",
            "\n",
            "    -f, --fetch           fetch the remote branches\n",
            "    --tags                import all tags and associated objects when fetching\n",
            "                          or do not fetch any tag at all (--no-tags)\n",
            "    -t, --track <branch>  branch(es) to track\n",
            "    -m, --master <branch>\n",
            "                          master branch\n",
            "    --mirror[=<push|fetch>]\n",
            "                          set up remote as a mirror to push to or fetch from\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push -u origin master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4leCNY_LG3GT",
        "outputId": "09924e51-235d-477c-fe58-5769c0751414"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Password for 'https://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@github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mh491HSpG_cK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TPE3(KNN classifier).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}