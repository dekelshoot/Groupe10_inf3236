{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GROUPE 10 inf3236\n",
        ". TCHOUPE KENGNE DEKEL JUNIOR 19M2394 \\\n",
        ". NKOUNGHAWE TOMEYUM ROSALIE CORINE 19M2333 \\\n",
        ". BAPOLA AMASSA RICHIL PERRIN 19M2661 \\\n",
        ". OBAMA MEVOUNGOU DRYSTAN GODGIFT 19M2132 \\\n",
        "\n",
        "\n",
        "### TP1: implémentation des resaux de neurones\n"
      ],
      "metadata": {
        "id": "6BwhXriIUJzO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCthVxGfTxCQ"
      },
      "source": [
        "## Importation des bibliothèques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHdDgmanTxCW"
      },
      "outputs": [],
      "source": [
        "import pylab as pylab\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imageio import imread # Je n'ai pas utilisé scipy.misc qui peut bien etre utilisé en installant Pillow avec la commande\n",
        "# pip install pillow\n",
        "from sklearn.metrics import precision_score\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzFP2tHmTxCY",
        "outputId": "30b0afb4-9dda-4596-cd02-8ecc49484dae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      0\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      0"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Afin de controler le caratère aléatoire de nos modèles\n",
        "seed = 128\n",
        "rng = np.random.RandomState(seed)\n",
        "\n",
        "#Définir les chemins d'accès\n",
        "root_dir = os.path.abspath('./')\n",
        "data_dir = os.path.join(root_dir,'data')\n",
        "sub_dir = os.path.join(root_dir, 'sub')\n",
        "\n",
        "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
        "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
        "\n",
        "sample_submission = pd.read_csv(os.path.join(sub_dir, 'sample_submission.csv'))\n",
        "sample_submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZWAjiTHTxCZ",
        "outputId": "23c0f67d-7085-4e19-d8ba-6b455f77d946"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['filename'], dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5FnyHwfTxCa"
      },
      "source": [
        "### Représentation des données: lecture de notre image et affichage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "GLF7OK1ITxCb",
        "outputId": "12c38bdb-11d6-42f9-dce3-a820aae42cac"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "img_name = rng.choice(train.filename)\n",
        "filepath = os.path.join( 'images', 'train', img_name)\n",
        "img = imread(filepath, as_gray = True)\n",
        "pylab.imshow(img, cmap = 'gray') # On rend notre image en noir sur blanc, on applique ce qu'on appelle le filtrage\n",
        "pylab.axis('off')\n",
        "pylab.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vTsA-IRTxCb"
      },
      "source": [
        "## Stockons toutes nos images sous forme de tableaux numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3uioSXxTxCc"
      },
      "outputs": [],
      "source": [
        "temp = []\n",
        "# Ajout des données de formation dans la liste\n",
        "for img_name in train.filename:\n",
        "    image_path = os.path.join('images', 'train', img_name)\n",
        "    img = imread(image_path, as_gray = True)\n",
        "    img = img.astype('float32')\n",
        "    temp.append(img) # On ajoute effectivement les images dans la liste temp\n",
        "\n",
        "train_x = np.stack(temp) # Afin de joindre la séquence de  tableaux de mm dimension le long du nouvel axe\n",
        "\n",
        "\n",
        "train_x /= 255.0\n",
        "train_x = train_x.reshape(-1, 784).astype('float32')\n",
        "\n",
        "# Ajout des données de test dans la liste \n",
        "temp = []\n",
        "for img_name in test.filename:\n",
        "    image_path = os.path.join('images', 'test', img_name)\n",
        "    img = imread(image_path, as_gray = True )\n",
        "    img = img.astype('float32')\n",
        "    temp.append(img) # Ajout des données de test à la suite des données d'entrainement fait plus haut\n",
        "    \n",
        "test_x = np.stack(temp) # Afin de joindre la séquence de  tableaux de mm dimension le long du nouvel axe\n",
        "\n",
        "test_x /= 255.0\n",
        "test_x = test_x.reshape(-1, 784).astype('float32')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p4LEcn_TxCd",
        "outputId": "fb54bd99-cf48-4bbe-b068-ca9df72b745b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "train_y = keras.utils.np_utils.to_categorical(train.label.values)\n",
        "print(train_y) # Affiche pour chaque label, les différentes valeurs de pixels, un label est une image\n",
        "\n",
        "# et cette image qui est une matrice de valeurs représentant un signal: 0 pour noir et 1 pour blanc en terme de couleur des pixels\n",
        "# On attribut les classes à chaque image de notre jeu d'entrainement en utilisant la méthode du \n",
        "# One-hold-encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCNgyl3TxCe"
      },
      "source": [
        "## Créons un ensemble de validation pour tester le bon fonctionnement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHkOMfEiTxCf"
      },
      "outputs": [],
      "source": [
        "# 70% pour la formation et 30% pour la validation de la formation\n",
        "\n",
        "split_size = int(train_x.shape[0]*0.7)\n",
        "\n",
        "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
        "train_y, val_y = train_y[:split_size], train_y[split_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq89Yw62TxCf"
      },
      "outputs": [],
      "source": [
        "#train.label.iloc[split_size:] # Extraction d'une colonne (ix est obsolète)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccO7KkP7TxCg"
      },
      "source": [
        "## Construction du modèle de réseaux de neurones\n",
        "\n",
        "*Architecture de notre modèle*:\n",
        "\n",
        "3 couches: entrée, cachée et sortie\n",
        "\n",
        "**entrée**: nombre de neurones 28x28 = 784 car notre image a cette taille, ce nombre de fragments, qui représente le nombre de caractéristiques\n",
        "\n",
        "**sortie**: nombre de neurones 10x1 = 10 car on a 10 classes cad les chiffres allant de 0 à 10 et ce sont ces chiffres que nous désirons identifier sur ces images avec un modèle qui pourra mieux le faire et très rapidement \n",
        "\n",
        "*Optimiseur*: nous utiliseront **Adam** comme optimiseur car c'est une variante efficace de l'algorithme de descente de gradient "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwzlojboTxCi"
      },
      "outputs": [],
      "source": [
        "# Définition des variables\n",
        "input_num_units = 784\n",
        "hidden_num_units = 50\n",
        "output_num_units = 10\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "# Imporons les modules keras\n",
        "\n",
        "# Créons un modèle\n",
        "\n",
        "model = keras.Sequential([\n",
        "    #Dense(output_dim = hidden_num_units, input_dim = input_num_units, activation = 'relu') \n",
        "    # On utilise la fonction d'activation ReLu\n",
        "    #Dense(output_dim = output_num_units, input_dim = hidden_num_units, activation = 'softmax')\n",
        "    # On utilise la fonction d'activation softmax pour cette Dense\n",
        "    layers.Dense(784, activation=\"relu\", name=\"layer1\"),\n",
        "    layers.Dense(50, activation=\"relu\", name=\"layer2\"),\n",
        "    layers.Dense(10,  activation=\"softmax\",name=\"layer3\"),\n",
        "    \n",
        "    \n",
        "])\n",
        "\n",
        "# Compilons le modèle avec les attributs nécessaires\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz7J04G1TxCj"
      },
      "source": [
        "####  Il est temps de former notre modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1FChVA_TxCj",
        "outputId": "2429392a-0028-401d-b4fa-c754b91b62d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.1389 - val_accuracy: 0.9730\n",
            "Epoch 2/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.1246 - val_accuracy: 0.9752\n",
            "Epoch 3/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1192 - val_accuracy: 0.9779\n",
            "Epoch 4/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1193 - val_accuracy: 0.9781\n",
            "Epoch 5/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1121 - val_accuracy: 0.9789\n"
          ]
        }
      ],
      "source": [
        "trained_model = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyqkcturTxCj"
      },
      "source": [
        "## ÉTAPE 3 : Évaluation du modèle\n",
        "Pour tester notre modèle de nos propres yeux, visualisons ses prédictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrGIoNj9TxCk",
        "outputId": "44bb03d1-a77f-47b6-f2b7-dd054fafc153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction is:  3\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = model.predict(test_x)\n",
        "classes=np.argmax(pred,axis=1)\n",
        "img_name = rng.choice(test.filename)\n",
        "filepath = os.path.join('images', 'test', img_name)\n",
        "\n",
        "img = imread(filepath, as_gray=True)\n",
        "\n",
        "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
        "\n",
        "print (\"Prediction is: \", classes[test_index])\n",
        "\n",
        "pylab.imshow(img, cmap='gray')\n",
        "pylab.axis('off')\n",
        "pylab.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttuo1aZlTxCk"
      },
      "outputs": [],
      "source": [
        " #Nous voyons que notre modèle fonctionne bien même en étant très simple. Maintenant, nous créons une soumission avec notre modèle\n",
        "\n",
        "#sample_submission.insert(2,\"filename\",test.filename)\n",
        "#sample_submission.insert(3,\"label2\",pred)\n",
        "#sample_submission.to_csv(os.path.join(sub_dir, 'sub02.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruYikWgxTxCk"
      },
      "source": [
        "## Hyperparamètres à surveiller dans les réseaux de neurones\n",
        "\n",
        "Type d'architecture\n",
        "\n",
        "nombre de couches\n",
        "\n",
        "nombre de neurones dans une couche\n",
        "\n",
        "paramètres de régularisation\n",
        "\n",
        "taux d'apprentissage\n",
        "\n",
        "type de technique d'optimisation\n",
        "\n",
        "taux d'abandon\n",
        "\n",
        "partage du poids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBw9PVuVTxCl"
      },
      "source": [
        "## Implémentation du modèle de réseau de neurones en tenant compte de ces hyperparamètres à surveiller"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5exGctoTxCl"
      },
      "source": [
        "## Importation des bibliothèques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saP7grGHTxCl"
      },
      "outputs": [],
      "source": [
        "import pylab as pylab\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imageio import imread\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDMRjfoxTxCm",
        "outputId": "8610db66-7cfa-4576-e27d-c677d4c236be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId  Label\n",
              "0        1      0\n",
              "1        2      0\n",
              "2        3      0\n",
              "3        4      0\n",
              "4        5      0"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Controle de l'aléa\n",
        "seed = 128\n",
        "rng = np.random.RandomState(seed)\n",
        "\n",
        "#Définir les chemins d'accès\n",
        "root_dir = os.path.abspath('./')\n",
        "data_dir = os.path.join(root_dir,'data')\n",
        "sub_dir = os.path.join(root_dir, 'sub')\n",
        "\n",
        "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
        "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
        "\n",
        "sample_submission = pd.read_csv(os.path.join(sub_dir, 'sample_submission.csv'))\n",
        "sample_submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa_BMReYTxCm"
      },
      "source": [
        "### Lire les jeux de données et les convertir en forme utilisable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj9RAzhITxCm"
      },
      "outputs": [],
      "source": [
        "temp = []\n",
        "# Ajout des données de formation dans la liste\n",
        "for img_name in train.filename:\n",
        "    image_path = os.path.join('images', 'train', img_name)\n",
        "    img = imread(image_path, as_gray = True)\n",
        "    img = img.astype('float32')\n",
        "    temp.append(img) # On ajoute effectivement les images dans la liste temp\n",
        "\n",
        "train_x = np.stack(temp) # Afin de joindre la séquence de  tableaux de mm dimension le long du nouvel axe\n",
        "\n",
        "\n",
        "train_x /= 255.0\n",
        "train_x = train_x.reshape(-1, 784).astype('float32')\n",
        "\n",
        "# Ajout des données de test dans la liste \n",
        "temp = []\n",
        "for img_name in test.filename:\n",
        "    image_path = os.path.join('images', 'test', img_name)\n",
        "    img = imread(image_path, as_gray = True )\n",
        "    img = img.astype('float32')\n",
        "    temp.append(img) # Ajout des données de test à la suite des données d'entrainement fait plus haut\n",
        "    \n",
        "test_x = np.stack(temp) # Afin de joindre la séquence de  tableaux de mm dimension le long du nouvel axe\n",
        "\n",
        "test_x /= 255.0\n",
        "test_x = test_x.reshape(-1, 784).astype('float32')\n",
        "\n",
        "train_y = keras.utils.np_utils.to_categorical(train.label.values) # Les labels des données de notre jeu d'entrainement\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raHo0ZOsTxCn"
      },
      "source": [
        "###  Divisez nos données de train en formation (train_x)  et validation(val_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VadZA7VwTxCn"
      },
      "outputs": [],
      "source": [
        "split_size = int(train_x.shape[0]*0.7)\n",
        "\n",
        "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
        "train_y, val_y = train_y[:split_size], train_y[split_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtD7ap2qTxCn"
      },
      "source": [
        "### Augmentons le nombre de neurones dans notre couche cachée afin de rendre le modèle plus large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbxdhOPPTxCn",
        "outputId": "0e9542a6-ace0-40a4-b2d4-b4e9d98061d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x186422e39d0>"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Définition des variables\n",
        "\n",
        "input_num_units = 784\n",
        "hidden_num_units = 500 # augmentation du nombre de neurones de la couche cachée\n",
        "output_num_units = 10\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "model =keras.Sequential([\n",
        "       layers.Dense(784, activation=\"relu\", name=\"layer1\"),\n",
        "       layers.Dense(500, activation=\"relu\", name=\"layer2\"),\n",
        "       layers.Dense(10,  activation=\"softmax\",name=\"layer3\"),\n",
        "    # On utilise la fonction d'activation softmax pour cette Dense\n",
        "    \n",
        "])\n",
        "\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK0HAn6TTxCo"
      },
      "source": [
        "### Testons le modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c7vjSZ7TxCo",
        "outputId": "c5c94157-88c2-42e0-cb27-766ffd7cadee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "268/268 [==============================] - 5s 18ms/step - loss: 0.2618 - accuracy: 0.9245 - val_loss: 0.1469 - val_accuracy: 0.9541\n",
            "Epoch 2/5\n",
            "268/268 [==============================] - 4s 16ms/step - loss: 0.0938 - accuracy: 0.9711 - val_loss: 0.1080 - val_accuracy: 0.9670\n",
            "Epoch 3/5\n",
            "268/268 [==============================] - 4s 16ms/step - loss: 0.0551 - accuracy: 0.9825 - val_loss: 0.1047 - val_accuracy: 0.9674\n",
            "Epoch 4/5\n",
            "268/268 [==============================] - 4s 16ms/step - loss: 0.0368 - accuracy: 0.9879 - val_loss: 0.0989 - val_accuracy: 0.9722\n",
            "Epoch 5/5\n",
            "268/268 [==============================] - 5s 17ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.1092 - val_accuracy: 0.9720\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "trained_model_500 = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3tsoKzkTxCo"
      },
      "source": [
        "### Augmentons la profondeur de notre modèle maintenant c'est à dire le nombre de couches "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koNdDq21TxCo",
        "outputId": "3ee273df-8b26-4e13-834a-439fc9a5fbd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x18649db3310>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define vars\n",
        "input_num_units = 784\n",
        "hidden1_num_units = 50\n",
        "hidden2_num_units = 50\n",
        "hidden3_num_units = 50\n",
        "hidden4_num_units = 50\n",
        "hidden5_num_units = 50\n",
        "output_num_units = 10\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "model =keras.Sequential([\n",
        "       layers.Dense(784, activation=\"relu\", name=\"layer1\"),\n",
        "       layers.Dense(50, activation=\"relu\", name=\"layer2\"),\n",
        "       layers.Dense(50, activation=\"relu\", name=\"layer3\"),\n",
        "       layers.Dense(50, activation=\"relu\", name=\"layer4\"),\n",
        "       layers.Dense(50, activation=\"relu\", name=\"layer5\"),\n",
        "       layers.Dense(50, activation=\"relu\", name=\"layer6\"),\n",
        "       layers.Dense(10,  activation=\"softmax\",name=\"layer7\"),\n",
        "    # On utilise la fonction d'activation softmax pour cette Dense\n",
        "    \n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30B7zL78TxCp"
      },
      "source": [
        "### Apprentisage et test du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzcsFfPRTxCp",
        "outputId": "80afb820-554f-4c09-d818-e56945ce1c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "268/268 [==============================] - 3s 11ms/step - loss: 0.4446 - accuracy: 0.8684 - val_loss: 0.2159 - val_accuracy: 0.9369\n",
            "Epoch 2/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.1463 - accuracy: 0.9568 - val_loss: 0.1362 - val_accuracy: 0.9594\n",
            "Epoch 3/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.0934 - accuracy: 0.9723 - val_loss: 0.1241 - val_accuracy: 0.9616\n",
            "Epoch 4/5\n",
            "268/268 [==============================] - 3s 10ms/step - loss: 0.0680 - accuracy: 0.9784 - val_loss: 0.1040 - val_accuracy: 0.9707\n",
            "Epoch 5/5\n",
            "268/268 [==============================] - 3s 11ms/step - loss: 0.0471 - accuracy: 0.9858 - val_loss: 0.1009 - val_accuracy: 0.9710\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "trained_model_5d = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn70jsqRTxCp"
      },
      "source": [
        "### Interprétation\n",
        "\n",
        "On se rend compte que nous n'avons pas atteint l'objectif\n",
        "\n",
        "Pour résoudre, on applique **l'abandon** qui consiste à désactiver aléatoirement les parties du modèle afin qu'il ne sur apprenne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-98gg4TTxCq"
      },
      "source": [
        "## Mise en oeuvre de l'abandon pour résoudre le problème"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFHEUOyhTxCq"
      },
      "outputs": [],
      "source": [
        "# Définition des variables\n",
        "input_num_units = 784\n",
        "hidden1_num_units = 50\n",
        "hidden2_num_units = 50\n",
        "hidden3_num_units = 50\n",
        "hidden4_num_units = 50\n",
        "hidden5_num_units = 50\n",
        "output_num_units = 10\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "dropout_ratio = 0.2\n",
        "\n",
        "\n",
        "model =keras.Sequential([\n",
        "       layers.Dense(input_num_units, activation=\"relu\", name=\"layer1\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden1_num_units, activation=\"relu\", name=\"layer2\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden2_num_units, activation=\"relu\", name=\"layer3\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden3_num_units, activation=\"relu\", name=\"layer4\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden4_num_units, activation=\"relu\", name=\"layer5\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden5_num_units, activation=\"relu\", name=\"layer6\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(output_num_units,  activation=\"softmax\",name=\"layer7\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "    # On utilise la fonction d'activation softmax pour cette Dense\n",
        "    \n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pNGpNZWTxCq"
      },
      "source": [
        "### Vérifions maintenant notre exactitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFX0ILW_TxCq",
        "outputId": "2cddc1aa-77a8-433e-b0de-bd4ebdc746bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "268/268 [==============================] - 5s 15ms/step - loss: 4.0264 - accuracy: 0.5350 - val_loss: 0.3129 - val_accuracy: 0.9149\n",
            "Epoch 2/5\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.4634 - accuracy: 0.7252 - val_loss: 0.2311 - val_accuracy: 0.9411\n",
            "Epoch 3/5\n",
            "268/268 [==============================] - 4s 15ms/step - loss: 3.4363 - accuracy: 0.7508 - val_loss: 0.1978 - val_accuracy: 0.9503\n",
            "Epoch 4/5\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.3813 - accuracy: 0.7592 - val_loss: 0.1646 - val_accuracy: 0.9605\n",
            "Epoch 5/5\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.3924 - accuracy: 0.7638 - val_loss: 0.1753 - val_accuracy: 0.9597\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "trained_model_5d_with_drop = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxVABeqJTxCr"
      },
      "source": [
        "Il semble que notre modèle ne fonctionne pas assez bien. L’une des raisons peut être que nous n’entraînons pas notre modèle à son plein potentiel.\n",
        "\n",
        "Augmentons nos époques de formation à 50 et vérifions-le!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpeefPR3TxCr"
      },
      "source": [
        "### Ajout du nombre d'époques pour résoudre le problème"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIvIdIy-TxCr"
      },
      "outputs": [],
      "source": [
        "# Définition des variables\n",
        "input_num_units = 784\n",
        "hidden1_num_units = 50\n",
        "hidden2_num_units = 50\n",
        "hidden3_num_units = 50\n",
        "hidden4_num_units = 50\n",
        "hidden5_num_units = 50\n",
        "output_num_units = 10\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "dropout_ratio = 0.2\n",
        "\n",
        "\n",
        "model =keras.Sequential([\n",
        "       layers.Dense(input_num_units, activation=\"relu\", name=\"layer1\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden1_num_units, activation=\"relu\", name=\"layer2\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden2_num_units, activation=\"relu\", name=\"layer3\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden3_num_units, activation=\"relu\", name=\"layer4\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden4_num_units, activation=\"relu\", name=\"layer5\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(hidden5_num_units, activation=\"relu\", name=\"layer6\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "       layers.Dense(output_num_units,  activation=\"softmax\",name=\"layer7\"),\n",
        "       layers.Dropout(dropout_ratio),\n",
        "    # On utilise la fonction d'activation softmax pour cette Dense\n",
        "    \n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzMdkKsSTxCr"
      },
      "source": [
        "### Vérifions l'exactitude du modèle avec le nombre d'époques augmenté"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "4mu7Pjg4TxCt",
        "outputId": "86170e62-bcb8-4ee3-ea24-f191728a385e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "268/268 [==============================] - 5s 15ms/step - loss: 4.0758 - accuracy: 0.4981 - val_loss: 0.3267 - val_accuracy: 0.9146\n",
            "Epoch 2/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.5212 - accuracy: 0.7188 - val_loss: 0.2215 - val_accuracy: 0.9433\n",
            "Epoch 3/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.4398 - accuracy: 0.7490 - val_loss: 0.1678 - val_accuracy: 0.9563\n",
            "Epoch 4/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: 3.3268 - accuracy: 0.7647 - val_loss: 0.1615 - val_accuracy: 0.9597\n",
            "Epoch 5/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.3452 - accuracy: 0.7697 - val_loss: 0.1477 - val_accuracy: 0.9620\n",
            "Epoch 6/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.3197 - accuracy: 0.7730 - val_loss: 0.1331 - val_accuracy: 0.9686\n",
            "Epoch 7/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.2967 - accuracy: 0.7759 - val_loss: 0.1479 - val_accuracy: 0.9656\n",
            "Epoch 8/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.3489 - accuracy: 0.7760 - val_loss: 0.1511 - val_accuracy: 0.9648\n",
            "Epoch 9/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.3872 - accuracy: 0.7748 - val_loss: 0.1227 - val_accuracy: 0.9706\n",
            "Epoch 10/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.3033 - accuracy: 0.7805 - val_loss: 0.1238 - val_accuracy: 0.9712\n",
            "Epoch 11/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: 3.3230 - accuracy: 0.7800 - val_loss: 0.1302 - val_accuracy: 0.9684\n",
            "Epoch 12/50\n",
            "268/268 [==============================] - 4s 16ms/step - loss: 3.2702 - accuracy: 0.7843 - val_loss: 0.1343 - val_accuracy: 0.9709\n",
            "Epoch 13/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.2765 - accuracy: 0.7846 - val_loss: 0.1180 - val_accuracy: 0.9734\n",
            "Epoch 14/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.2761 - accuracy: 0.7867 - val_loss: 0.1165 - val_accuracy: 0.9738\n",
            "Epoch 15/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: 3.2762 - accuracy: 0.7869 - val_loss: 0.1258 - val_accuracy: 0.9744\n",
            "Epoch 16/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.5789 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "268/268 [==============================] - 5s 18ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "268/268 [==============================] - 4s 13ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "268/268 [==============================] - 4s 16ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "268/268 [==============================] - 4s 14ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "268/268 [==============================] - 4s 15ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1000\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "trained_model_5d_with_drop = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "name": "TP4(reseaux_neurones).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}